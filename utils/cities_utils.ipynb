{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4b5733bb-ecd7-4938-a6b6-308e6fcdfe93","showTitle":false,"title":""}},"source":["####Function to load City from data folder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%sql\n","drop table if exists dim_city;"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9867e553-a72a-45db-8789-5fd8538789bf","showTitle":false,"title":""}},"outputs":[],"source":["def load_cities():\n","    from pyspark.sql.functions import col\n","    # read city from json file\n","    file_path = \"dbfs:/FileStore/shared_uploads/ujjwal.baral3980@kistcollege.edu.np/city_list_json.gz\"\n","    options = {'multiLine': True}\n","    df = spark.read.json(file_path, **options).select('*', 'coord.*')\n","    df = df.select(col('id').cast('int'), 'name', 'country', col('lat').cast('float'), col('lon').cast('float'))\n","    df = df.filter(df[\"country\"] == \"NP\")   \n","    df.write.format('delta').mode('overwrite').saveAsTable('dim_city')\n","    df.display()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Api Decorator","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
