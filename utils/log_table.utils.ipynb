{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0b25fb4b-3c0a-4aa3-9be0-dff7f8329e4d","showTitle":false,"title":""}},"source":["####Decorater Function to create Log table"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ad4a3857-9a18-47d4-91df-06abe37ad91e","showTitle":false,"title":""}},"outputs":[],"source":["def create_log_table():\n"," \n","    query = \"\\\n","        CREATE TABLE IF NOT EXISTS weather_log_table (\\\n","        id STRING,\\\n","        load_type STRING,\\\n","        table_name STRING,\\\n","        process_start_time TIMESTAMP,\\\n","        process_end_time TIMESTAMP,\\\n","        status STRING,\\\n","        comments STRING,\\\n","        start_date_time TIMESTAMP,\\\n","        end_date_time TIMESTAMP,\\\n","        created_on TIMESTAMP,\\\n","        created_by STRING\\\n","        )\\\n","        USING DELTA;\\\n","    \"\n","    spark.sql(query)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f38ee245-3284-4f4c-b8e4-2b231bd010cc","showTitle":false,"title":""}},"outputs":[],"source":["\n","\n","def keep_log(func):\n","    def wrapper(*args, **kwargs):\n","        \n","        import uuid\n","        from datetime import datetime\n","        from pyspark.sql.functions import col, udf\n","        from pyspark.sql.types import TimestampType\n","\n","        id = str(uuid.uuid4())\n","        load_type = args[0]\n","        table_name = args[1]\n","        process_start_dt = datetime.now()\n","        name = 'Ujjwal Baral'\n","        status = 'EXTRACTING'\n","\n","        query = f\"insert into weather_log_table (id, load_type, table_name, process_start_time, status, created_on, created_by)\\\n","            values ('{id}', '{load_type}', '{table_name}', '{process_start_dt}', '{status}', '{process_start_dt}', '{name}')\"\n","        spark.sql(query)\n","        \n","        try:\n","            df, start, end = func(*args[2:], **kwargs)\n","            status = 'COMPLETED'\n","        except Exception as e:\n","            status = 'ERROR'\n","            process_end_dt = datetime.now()\n","            query = f\"update weather_log_table \\\n","                        set process_end_time = '{process_end_dt}', status='{status}', comments='{e}',\\\n","                        where id='{id}'\"\n","            spark.sql(query)\n","            dbutils.notebook.exit(1)\n","        \n","        \n","        udf_id = udf(lambda : id)\n","        udf_created_on = udf(lambda : process_start_dt, TimestampType())\n","        udf_created_by = udf(lambda : name)\n","        \n","        df = df.withColumn('load_run_id', udf_id())\n","        df = df.withColumn('created_on', udf_created_on())\n","        df = df.withColumn('created_by', udf_created_by())\n","        \n","        df.write.format('delta').mode('ovewrite').saveAsTable(table_name)\n","        \n","        process_end_dt = datetime.now()\n","        query = f\"update weather_log_table \\\n","                    set process_end_time = '{process_end_dt}', status='{status}', start_date_time='{start}',\\\n","                        end_date_time='{end}'\\\n","                    where id='{id}'\"\n","        spark.sql(query)\n","        \n","        return df\n","    \n","    return wrapper\n","\n","     "]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"log_table.utils","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
