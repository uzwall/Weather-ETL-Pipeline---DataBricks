{"cells":[{"cell_type":"markdown","source":["####Decorater Function to create Log table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b25fb4b-3c0a-4aa3-9be0-dff7f8329e4d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def create_log_table():\n \n    query = \"\\\n        CREATE TABLE IF NOT EXISTS weather_log_table (\\\n        id STRING,\\\n        load_type STRING,\\\n        table_name STRING,\\\n        process_start_time TIMESTAMP,\\\n        process_end_time TIMESTAMP,\\\n        status STRING,\\\n        comments STRING,\\\n        start_date_time TIMESTAMP,\\\n        end_date_time TIMESTAMP,\\\n        created_on TIMESTAMP,\\\n        created_by STRING\\\n        )\\\n        USING DELTA;\\\n    \"\n    spark.sql(query)\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ad4a3857-9a18-47d4-91df-06abe37ad91e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n\ndef keep_log(func):\n    def wrapper(*args, **kwargs):\n        \n        import uuid\n        from datetime import datetime\n        from pyspark.sql.functions import col, udf\n        from pyspark.sql.types import TimestampType\n\n        id = str(uuid.uuid4())\n        load_type = args[0]\n        table_name = args[1]\n        process_start_dt = datetime.now()\n        name = 'Ujjwal Baral'\n        status = 'EXTRACTING'\n\n        query = f\"insert into weather_log_table (id, load_type, table_name, process_start_time, status, created_on, created_by)\\\n            values ('{id}', '{load_type}', '{table_name}', '{process_start_dt}', '{status}', '{process_start_dt}', '{name}')\"\n        spark.sql(query)\n        \n        try:\n            df, start, end = func(*args[2:], **kwargs)\n            status = 'COMPLETED'\n        except Exception as e:\n            status = 'ERROR'\n            process_end_dt = datetime.now()\n            query = f\"update weather_log_table \\\n                        set process_end_time = '{process_end_dt}', status='{status}', comments='{e}',\\\n                        where id='{id}'\"\n            spark.sql(query)\n            dbutils.notebook.exit(1)\n        \n        \n        udf_id = udf(lambda : id)\n        udf_created_on = udf(lambda : process_start_dt, TimestampType())\n        udf_created_by = udf(lambda : name)\n        \n        df = df.withColumn('load_run_id', udf_id())\n        df = df.withColumn('created_on', udf_created_on())\n        df = df.withColumn('created_by', udf_created_by())\n        \n        df.write.format('delta').mode('append').saveAsTable(table_name)\n        \n        process_end_dt = datetime.now()\n        query = f\"update weather_log_table \\\n                    set process_end_time = '{process_end_dt}', status='{status}', start_date_time='{start}',\\\n                        end_date_time='{end}'\\\n                    where id='{id}'\"\n        spark.sql(query)\n        \n        return df\n    \n    return wrapper\n\n     "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f38ee245-3284-4f4c-b8e4-2b231bd010cc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"log_table.utils","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
